{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Title Name : MNIST 데이터셋 모델링 연습**\n",
    "\n",
    "<p style=\"font-weight:bolder; font-size : 21px\">\n",
    "    Step : Create file [step_1]\n",
    "<p>\n",
    "<p style=\"font-weight:bolder; font-size : 21px\">\n",
    "   RegDate : 2023.12.07\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "용어정리\n",
    "```\n",
    "- 파라미터      : 세팅\n",
    "- 함수,클래스   : 정의\n",
    "- 클래스객체    : 생성\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 프로세스\n",
    "```\n",
    "1.문제정의 >>> 2.EDA >>> 3.모델링 >>> 4.성능개선 >>> 5.모델링 >>> 6.제출 or 채점\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "진행순서(모델링 프로세스)\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "환경설정 >>> 전처리 >>> 모델생성 >>> optimizer,loss 생성 >>> \n",
    "[훈련 > 검증(생략가능) > 예측] >>> [모델저장(생략가능) > 모델불러오기](생략가능) >>> \n",
    "최종채점(생략가능) >>> 제출\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "1.  환경설정\n",
    "2.  전처리\n",
    "3.  모델생성\n",
    "4.  optimizer,loss 생성\n",
    "5.  훈련\n",
    "6.  검증\n",
    "7.  예측\n",
    "8.  모델저장\n",
    "9.  모델불러오기\n",
    "10. 최종채점\n",
    "11. 제출\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경설정\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 모듈 불러오기\n",
    "#======================================================\n",
    "\n",
    "# 시스템\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# 데이터분석 4종 세트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 파이토치\n",
    "from torch import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# CV용 토치비전\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "# 사이킷런\n",
    "import sklearn\n",
    "\n",
    "# 검증용 Kfold\n",
    "# import ~~~~~\n",
    "\n",
    "# 유틸\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화테마\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# 작업환경\n",
    "IS_GOOGLE = True if 'google.colab'                in sys.modules  else False\n",
    "IS_KAGGLE = True if 'KAGGLE_KERNEL_RUN_TYPE'      in os.environ   else False\n",
    "IS_LOCAL  = True if not (IS_GOOGLE or IS_KAGGLE)                  else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ 시드설정\n",
    "#======================================================\n",
    "\n",
    "SEED = 2023\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "torch.backends.cudnn.deterministic  =  True\n",
    "torch.backends.cudnn.benchmark      =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ 데이터 경로 설정\n",
    "#======================================================\n",
    "if IS_GOOGLE :\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_path = '/content/drive/~~프로젝트패스~~설정~~/'\n",
    "elif IS_KAGGLE :\n",
    "    base_path = 'kaggle/input/프로젝트-패스/'\n",
    "    \n",
    "elif IS_LOCAL :\n",
    "    # base_path = './data/'\n",
    "    base_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy_Ver   :  1.24.3버전\n",
      "--------------------------------------------------\n",
      "pandas_Ver  :  2.0.3버전\n",
      "--------------------------------------------------\n",
      "seaborn_Ver :  0.13.0버전\n",
      "--------------------------------------------------\n",
      "torch_Ver   :  2.1.1+cu118버전\n",
      "--------------------------------------------------\n",
      "cpu_count   :  12코어\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 버전 체크\n",
    "#======================================================\n",
    "\n",
    "print(f'numpy_Ver   :  {np.__version__}버전')\n",
    "print('-'*50)\n",
    "print(f'pandas_Ver  :  {pd.__version__}버전')\n",
    "print('-'*50)\n",
    "print(f'seaborn_Ver :  {sns.__version__}버전')\n",
    "print('-'*50)\n",
    "print(f'torch_Ver   :  {torch.__version__}버전')\n",
    "print('-'*50)\n",
    "print(f'cpu_count   :  {os.cpu_count()}코어')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전처리\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ 하이퍼파라미터 `초벌` 세팅\n",
    "#======================================================\n",
    "num_workers = int(os.cpu_count())-6 if os.cpu_count() else int(os.cpu_count())\n",
    "batch_size = 16\n",
    "learning_rate = 1e-2\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ 트랜스폼 객체생성\n",
    "#======================================================\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ 트테설정\n",
    "#======================================================\n",
    "train_dataset      =   MNIST(root=base_path, train=True,  transform=transform, download=True)\n",
    "test_dataset       =   MNIST(root=base_path, train=False, transform=transform, download=True)\n",
    "train_dataloader   =   DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "test_dataloader    =   DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor X [N,C,H,W] : torch.Size([16, 1, 28, 28])\n",
      "shape of tensor y           : torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ [데이터추출] 학습데이터 shape체크 및 추출\n",
    "#======================================================\n",
    "for X, y in train_dataloader:\n",
    "    print(f'shape of tensor X [N,C,H,W] : {X.shape}')\n",
    "    print(f'shape of tensor y           : {y.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델생성\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# [스도코드작성] 모델 파라미터 플로우코드 \n",
    "#======================================================\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~[NN]~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#   \n",
    "# init    : (N,1,28,28) \n",
    "# flatten : (N,1*28*28) \n",
    "# Linear1 : (N,1*28*28) -> (N,1*28*28)\n",
    "# Linear2 : (N,1*28*28) -> (N,1*28*28)\n",
    "#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~[CNN]~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "#----Conv1----\n",
    "# (N,1,28,28)    ->  (N,6,28,28)    ->RELU->  (N,12,28,28)    -> (N,6,28,28) ->RELU-> \n",
    "#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사용 디바이스 : GPU\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ [파라미터 세팅] 디바이스 세팅\n",
    "#======================================================\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "str_device = 'GPU' if torch.cuda.is_available() else 'CPU'\n",
    "print(f'현재 사용 디바이스 : {str_device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ [파라미터세팅] 모델 파라미터 세팅\n",
    "#======================================================\n",
    "\n",
    "channel_size = int(X.shape[1])\n",
    "\n",
    "# conv층\n",
    "first_channel = channel_size\n",
    "last_channel  = 64\n",
    "\n",
    "# affine층\n",
    "input_dim = 1*28*28\n",
    "dense_dim = 512\n",
    "num_classes = len(np.unique(next(iter(test_dataloader))[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ [클래스정의] 모델 클래스 정의\n",
    "#======================================================\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim,dense_dim)\n",
    "        self.linear2 = nn.Linear(dense_dim,num_classes)\n",
    "        self.linear_relu_stack = nn.Sequential(self.linear1,self.relu,self.linear2,self.relu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (relu): ReLU()\n",
       "  (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=9, bias=True)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=9, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 모델 생성\n",
    "#======================================================\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "            Linear-3                  [-1, 512]         401,920\n",
      "              ReLU-4                  [-1, 512]               0\n",
      "              ReLU-5                  [-1, 512]               0\n",
      "            Linear-6                    [-1, 9]           4,617\n",
      "            Linear-7                    [-1, 9]           4,617\n",
      "              ReLU-8                    [-1, 9]               0\n",
      "              ReLU-9                    [-1, 9]               0\n",
      "================================================================\n",
      "Total params: 813,074\n",
      "Trainable params: 813,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 3.10\n",
      "Estimated Total Size (MB): 3.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 피쳐 플로우 확인\n",
    "#======================================================\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. optimizer 및 loss 설정   <!!!(훈련용 함수준비)>\n",
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ optimizer 객체생성\n",
    "#======================================================\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# ▶ loss function 객체생성\n",
    "#======================================================\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #======================================================\n",
    "# # ▶ 훈련용(train) 함수 정의\n",
    "# #======================================================\n",
    "# def train(dataloader,model,optimizer,criterion) :\n",
    "#     '''\n",
    "#     Info   : 훈련용 프로세스를 정의합니다(순전파->역전파->결과리턴)                                 \\n\n",
    "#     Params : 총 4개의 파라미터(Dataloader, Model, Optimizer, Loss Function)를 인자로 받습니다.      \\n\n",
    "#     Return : Average Loss(평균손실률)을 반환합니다.                                                 \\n\n",
    "#     '''\n",
    "#     # 평가지표 초기화\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     # [학습용] 반복 추출\n",
    "#     for batch , (X,y) in enumerate(dataloader) :\n",
    "        \n",
    "#         # 파라미터 \n",
    "#         X = X.to(device)\n",
    "#         y = y.to(device)\n",
    "        \n",
    "#         # 순전파\n",
    "#         pred  = model(X)\n",
    "#         loss  = criterion(pred,y)\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         # 역전파\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     # 결과 출력\n",
    "#     loss_avg = total_loss / len(dataloader)\n",
    "#     return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #======================================================\n",
    "# # ▶ 예측용(test) 함수 정의\n",
    "# #======================================================\n",
    "# def test(dataloader,model,criterion) :\n",
    "#     '''\n",
    "#     Info   : 훈련용 프로세스를 정의합니다(순전파->역전파->결과리턴)                                 \\n\n",
    "#     Params : 총 3개의 파라미터(Dataloader, Model, Optimizer, Loss Function)를 인자로 받습니다.      \\n\n",
    "#     Return : Average Loss(평균손실률)을 반환합니다.                                                 \\n\n",
    "#     '''\n",
    "#     # 평가지표 초기화\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     # 추론모드(가중치 비활성)\n",
    "#     with torch.no_grad() :\n",
    "\n",
    "#         # [예측용] 반복 추출\n",
    "#         for idx , (X,y) in enumerate(dataloader) :\n",
    "\n",
    "#             # 파라미터\n",
    "#             X = X.to(device)\n",
    "#             y = y.to(device)\n",
    "\n",
    "#             # Total loss Calculation\n",
    "#             pred        = model(X)\n",
    "#             loss        = criterion(pred,y)\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "\n",
    "#         # 결과출력\n",
    "#         loss_avg = total_loss / len(dataloader)\n",
    "#         return loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 훈련\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Adam' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TETRA\\Desktop\\모델링연습\\Practice\\[NN]MNIST_ver0.0.1.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     train(train_dataloader, model, optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     test(test_dataloader, model, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\TETRA\\Desktop\\모델링연습\\Practice\\[NN]MNIST_ver0.0.1.ipynb Cell 28\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 예측 오류 계산\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred,y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Adam' object is not callable"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            \n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, optimizer, criterion)\n",
    "    test(test_dataloader, model, criterion)\n",
    "print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TETRA\\Desktop\\모델링연습\\Practice\\[NN]MNIST_ver0.0.1.ipynb Cell 28\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 미니배치 트레이닝\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)) :\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     train(dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,model\u001b[39m=\u001b[39;49mmodel,optimizer\u001b[39m=\u001b[39;49moptimizer,criterion\u001b[39m=\u001b[39;49mcriterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     test(dataloader\u001b[39m=\u001b[39mtest_dataloader,model\u001b[39m=\u001b[39mmodel,criterion\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m end \u001b[39m=\u001b[39m time()\n",
      "\u001b[1;32mc:\\Users\\TETRA\\Desktop\\모델링연습\\Practice\\[NN]MNIST_ver0.0.1.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m pred  \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss  \u001b[39m=\u001b[39m criterion(pred,y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 훈련!\n",
    "#======================================================\n",
    "\n",
    "start = time()\n",
    "\n",
    "# 미니배치 트레이닝\n",
    "for epoch in tqdm(range(epochs)) :\n",
    "    train(dataloader=train_dataloader,model=model,optimizer=optimizer,criterion=criterion)\n",
    "    test(dataloader=test_dataloader,model=model,criterion=criterion)\n",
    "\n",
    "end = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TETRA\\Desktop\\모델링연습\\Practice\\[NN]MNIST_ver0.0.1.ipynb Cell 29\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#======================================================\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# ▶ 총 소요시간\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#======================================================\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m  end \u001b[39m-\u001b[39m start\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m hours   \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(elapsed_time \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3600\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TETRA/Desktop/%EB%AA%A8%EB%8D%B8%EB%A7%81%EC%97%B0%EC%8A%B5/Practice/%5BNN%5DMNIST_ver0.0.1.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m minutes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((elapsed_time \u001b[39m%\u001b[39m \u001b[39m3600\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m60\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "# ▶ 총 소요시간\n",
    "#======================================================\n",
    "elapsed_time =  end - start\n",
    "hours   = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "seconds = int(elapsed_time % 3600)\n",
    "print(f' 총 소요시간 : {hours}시간 {minutes}분 {seconds}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
